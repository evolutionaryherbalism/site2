name: Visual Regression Tests

on:
  schedule:
    - cron: '*/15 * * * *'
  workflow_dispatch:

concurrency:
  group: visual-regression
  cancel-in-progress: true

permissions:
  contents: read

jobs:
  check-schedule:
    runs-on: ubuntu-latest
    outputs:
      sites_due: ${{ steps.check.outputs.sites_due }}
    steps:
      - name: Checkout config only
        if: github.event_name != 'workflow_dispatch'
        uses: actions/checkout@v4
        with:
          sparse-checkout: urls.yml

      - name: Check if any sites are scheduled now
        id: check
        env:
          URLS_CONFIG: ${{ vars.URLS_CONFIG }}
        run: |
          # Manual runs always proceed
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo "Manual run â€” testing all sites."
            echo "sites_due=true" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          # Extract period values from config
          if [ -n "$URLS_CONFIG" ]; then
            PERIODS=$(echo "$URLS_CONFIG" | grep -oP 'period:\s*\K[0-9]+[mhd]')
          else
            PERIODS=$(grep -oP 'period:\s*\K[0-9]+[mhd]' urls.yml 2>/dev/null)
          fi

          if [ -z "$PERIODS" ]; then
            echo "No periods found in config."
            echo "sites_due=false" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          MINUTES_SINCE_EPOCH=$(( $(date +%s) / 60 ))

          for period in $PERIODS; do
            value=${period%[mhd]}
            unit=${period: -1}
            case $unit in
              m) mins=$value ;;
              h) mins=$((value * 60)) ;;
              d) mins=$((value * 1440)) ;;
            esac

            remainder=$((MINUTES_SINCE_EPOCH % mins))
            if [ "$remainder" -lt 15 ]; then
              echo "Site with period ${period} is due (remainder=${remainder})."
              echo "sites_due=true" >> "$GITHUB_OUTPUT"
              exit 0
            fi
          done

          echo "No sites due at this time."
          echo "sites_due=false" >> "$GITHUB_OUTPUT"

  test:
    needs: check-schedule
    if: needs.check-schedule.outputs.sites_due == 'true'
    runs-on: ubuntu-latest
    env:
      WEBHOOK_URL: ${{ secrets.WEBHOOK_URL }}
      WEBHOOK_URL_ALWAYS: ${{ secrets.WEBHOOK_URL_ALWAYS }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Restore baseline snapshots
        id: cache-baseline
        uses: actions/cache/restore@v4
        with:
          path: tests/visual-regression.spec.js-snapshots
          key: visual-baselines-v1
          restore-keys: visual-baselines-

      - name: Validate baselines exist
        id: baseline-check
        run: |
          if [ "${{ steps.cache-baseline.outputs.cache-hit }}" != "true" ] || \
             [ ! -d "tests/visual-regression.spec.js-snapshots" ] || \
             [ -z "$(ls -A tests/visual-regression.spec.js-snapshots 2>/dev/null)" ]; then
            echo "baseline_exists=false" >> "$GITHUB_OUTPUT"
          else
            echo "baseline_exists=true" >> "$GITHUB_OUTPUT"
          fi

      - name: Notify baseline missing
        if: steps.baseline-check.outputs.baseline_exists == 'false' && env.WEBHOOK_URL != ''
        continue-on-error: true
        run: |
          curl -sf -X POST "$WEBHOOK_URL" \
            -H "Content-Type: application/json" \
            -d "{\"text\":\"\u26A0\uFE0F No baseline snapshots found.\",\"blocks\":[{\"type\":\"section\",\"text\":{\"type\":\"mrkdwn\",\"text\":\"*\u26A0\uFE0F Visual Regression: No Baselines Found*\nRun the <https://github.com/${{ github.repository }}/actions/workflows/update-baselines.yml|Update Visual Baselines> workflow first.\"}}]}"

      - name: Exit if baseline missing
        if: steps.baseline-check.outputs.baseline_exists == 'false'
        run: |
          echo "::error::No baseline found. Run 'Update Visual Baselines' workflow first."
          exit 1

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Cache Playwright browsers
        uses: actions/cache@v4
        id: playwright-cache
        with:
          path: ~/.cache/ms-playwright
          key: playwright-${{ runner.os }}-${{ hashFiles('package-lock.json') }}

      - name: Install Playwright browsers
        if: steps.playwright-cache.outputs.cache-hit != 'true'
        run: npx playwright install --with-deps chromium

      - name: Install Playwright system dependencies
        if: steps.playwright-cache.outputs.cache-hit == 'true'
        run: npx playwright install-deps chromium

      - name: Run visual regression tests
        id: test
        continue-on-error: true
        env:
          URLS_CONFIG: ${{ vars.URLS_CONFIG }}
        run: npm test

      - name: Upload test artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-report-${{ github.run_id }}
          path: |
            playwright-report/
            test-results/
          retention-days: 30

      - name: Upload screenshots to R2
        if: always() && vars.R2_BUCKET_NAME != ''
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          AWS_ENDPOINT_URL: https://${{ vars.R2_ACCOUNT_ID }}.r2.cloudflarestorage.com
          BUCKET: ${{ vars.R2_BUCKET_NAME }}
          R2_PUBLIC_URL: ${{ vars.R2_PUBLIC_URL }}
          RUN_ID: ${{ github.run_id }}
        run: |
          TIMESTAMP=$(date +%s)
          echo "{}" > r2-paths.json

          # Upload current, diff, and actual screenshots
          while IFS= read -r file; do
            [ -n "$file" ] || continue
            filename=$(basename "$file")

            if [[ "$filename" =~ ^(.+)-(current|diff|actual)\.png$ ]]; then
              sitename="${BASH_REMATCH[1]}"
              filetype="${BASH_REMATCH[2]}"
            else
              continue
            fi

            s3_path="${RUN_ID}/${sitename}/${sitename}-${filetype}-${TIMESTAMP}.png"
            aws s3 cp "$file" "s3://${BUCKET}/${s3_path}" --endpoint-url "$AWS_ENDPOINT_URL"

            full_url="${R2_PUBLIC_URL}/${s3_path}"
            jq --arg key "${sitename}-${filetype}" --arg url "$full_url" \
              '.[$key] = $url' r2-paths.json > r2-paths-tmp.json && mv r2-paths-tmp.json r2-paths.json

            echo "Uploaded: ${full_url}"
          done < <(find test-results \( -name "*-current.png" -o -name "*-diff.png" -o -name "*-actual.png" \) 2>/dev/null)

          # Add baseline URLs for each tested site
          if [ -n "$R2_PUBLIC_URL" ]; then
            while IFS= read -r file; do
              [ -n "$file" ] || continue
              sitename=$(basename "$file" | sed 's/-current\.png$//')
              jq --arg key "${sitename}-baseline" --arg url "${R2_PUBLIC_URL}/baselines/${sitename}.png" \
                '.[$key] = $url' r2-paths.json > r2-paths-tmp.json && mv r2-paths-tmp.json r2-paths.json
            done < <(find test-results -name "*-current.png" 2>/dev/null)
          fi

      - name: Send failure notification
        if: steps.test.outcome == 'failure' && env.WEBHOOK_URL != ''
        env:
          URLS_CONFIG: ${{ vars.URLS_CONFIG }}
          R2_PUBLIC_URL: ${{ vars.R2_PUBLIC_URL }}
        run: node scripts/notify.js --mode failure

      - name: Send always notification
        if: |
          !cancelled()
          && (steps.test.outcome == 'success' || steps.test.outcome == 'failure')
          && env.WEBHOOK_URL_ALWAYS != ''
        env:
          URLS_CONFIG: ${{ vars.URLS_CONFIG }}
          R2_PUBLIC_URL: ${{ vars.R2_PUBLIC_URL }}
        run: node scripts/notify.js --mode always

      - name: Fail job if tests failed
        if: steps.test.outcome == 'failure'
        run: exit 1
